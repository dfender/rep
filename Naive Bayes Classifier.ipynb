{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadCsv(filename):\n",
    "    # Numpy function to generate array from txt or csv\n",
    "    return np.genfromtxt(filename, delimiter = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def splitDataset(dataset, splitRatio, number_of_rows):\n",
    "    # Shuffled data\n",
    "    data_copy = dataset.copy()\n",
    "    np.random.shuffle(data_copy)\n",
    "    \n",
    "    # Cut dataset:\n",
    "    data_part = data_copy[:int(number_of_rows)]\n",
    "    \n",
    "    # Training set size \n",
    "    trainSize = int(len(data_part) * splitRatio)\n",
    "    \n",
    "    #Split data\n",
    "    data_train = data_part[: trainSize]\n",
    "    data_test = data_part[trainSize : dataset.shape[0]]\n",
    "    \n",
    "    return data_train, data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separateByClass(dataset):\n",
    "    # Here we limit our classes to 0 and 1\n",
    "    # You need to generalize this for arbitrary number of classes\n",
    "    classes = np.unique(dataset[:, -1])\n",
    "    return dict((k, dataset[np.where(dataset[:, -1] == k), :]) for k in classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def summarize(dataset):\n",
    "    # Calculate means and standart deviations with one degree of freedom for each attribute\n",
    "    # We do it by column which is axis 1\n",
    "    # Also we remove last elements (guess why?)\n",
    "    means = dataset.mean(axis = 1)[0][:-1]\n",
    "    stds = dataset.std(axis = 1, ddof = 1)[0][:-1]\n",
    "    \n",
    "    # Think what we do here?\n",
    "    return means, stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def summarizeByClass(dataset):\n",
    "    # Divide dataset by class and summarize it\n",
    "    separated = separateByClass(dataset)\n",
    "    \n",
    "    summaries = {}\n",
    "    \n",
    "    for classValue, instances in separated.items():\n",
    "        summaries[classValue] = summarize(instances)\n",
    "    \n",
    "    return summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculateProbability(x, mean, stdev):\n",
    "    # Calculate probability by x, mean and std\n",
    "    # 1/(sqrt(2pi)*std)*exp(-(x-mean)^2/(2std^2))\n",
    "    return np.prod(np.exp(-(x-mean)**2/(2*stdev**2))/(np.sqrt(2*np.pi)*stdev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculateClassProbabilities(summaries, inputVector):\n",
    "    # Calculate probabilities for input vector from test set\n",
    "    probabilities = {}\n",
    "    \n",
    "    for classValue, classSummaries in summaries.items():\n",
    "        \n",
    "        means = classSummaries[0]\n",
    "        stds  = classSummaries[1]\n",
    "        \n",
    "        # Calculate corresonding probabilities and multiply them\n",
    "        probabilities[classValue] = calculateProbability(inputVector[:-1], means, stds)\n",
    "        \n",
    "    return probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(summaries, inputVector):\n",
    "    # Calculate probabilities\n",
    "    probabilities = calculateClassProbabilities(summaries, inputVector)\n",
    "    \n",
    "    # Init values of probability and label\n",
    "    bestLabel, bestProb = None, -1\n",
    "    \n",
    "    # Check probability of which class is better\n",
    "    for classValue, probability in probabilities.items():\n",
    "        if bestLabel is None or probability > bestProb:\n",
    "            bestProb = probability\n",
    "            bestLabel = classValue\n",
    "    \n",
    "    return bestLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getPredictions(summaries, testSet):\n",
    "    # For each probability find optimal labels\n",
    "    predictions = []\n",
    "    \n",
    "    for i in range(len(testSet)):\n",
    "        result = predict(summaries, testSet[i])\n",
    "        predictions.append(result)\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getAccuracy(testSet, predictions):\n",
    "    # Check accuracy\n",
    "    correct = 0\n",
    "    \n",
    "    for i in range(len(testSet)):\n",
    "        if testSet[i][-1] == predictions[i]:\n",
    "            correct += 1\n",
    "    return (correct/float(len(testSet))) * 100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Set initial data\n",
    "    filename = 'Skin_NonSkin.txt'\n",
    "    \n",
    "    # Set split ratio\n",
    "    splitRatio = 0.67\n",
    "    \n",
    "    # Load dataset and return numpy array\n",
    "    dataset = loadCsv(filename)\n",
    "    \n",
    "    #dataset = normilize2(dataset)\n",
    "    number_of_rows = 500\n",
    "    \n",
    "    # Split dataset\n",
    "    trainingSet, testSet = splitDataset(dataset, splitRatio, number_of_rows)\n",
    "    \n",
    "    # Log row amounts\n",
    "    print('Split {0} rows into train={1} and test={2} rows'.format(len(dataset), len(trainingSet), len(testSet)))\n",
    "    \n",
    "    # Prepare model\n",
    "    summaries = summarizeByClass(trainingSet)\n",
    "    \n",
    "    # Test model\n",
    "    predictions = getPredictions(summaries, testSet)\n",
    "    \n",
    "    accuracy = getAccuracy(testSet, predictions)\n",
    "    \n",
    "    print('Accuracy: {0}%'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 245057 rows into train=335 and test=165 rows\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-100-58ca95c5b364>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-99-439d8b6f4521>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;31m# Test model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m     \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetPredictions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msummaries\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestSet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetAccuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestSet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-95-6e5720ed116c>\u001b[0m in \u001b[0;36mgetPredictions\u001b[1;34m(summaries, testSet)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestSet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msummaries\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestSet\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0mpredictions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-94-d95b84471e7b>\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(summaries, inputVector)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;31m# Check probability of which class is better\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mclassValue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprobability\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mprobabilities\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mbestLabel\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mprobability\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mbestProb\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m             \u001b[0mbestProb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprobability\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m             \u001b[0mbestLabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclassValue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
